{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c0d87510-2e06-4a18-92fa-b8832b715805",
   "metadata": {},
   "source": [
    "#### \n",
    "In the below project the cleaning of the tweets from text column , tokenization of tweets and removal of stop words has been done."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "227b7411-e2b6-4fd5-bd37-891849e3f680",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e15aec84-1718-4412-9ae0-f2eace35a837",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train=pd.read_csv(\"train.csv\")\n",
    "df_test=pd.read_csv(\"test.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "746cb0f3-d07f-41b4-9bf9-3eb197c73f02",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(7613, 5)\n",
      "(3263, 4)\n"
     ]
    }
   ],
   "source": [
    "print(df_train.shape)\n",
    "print(df_test.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "157bd815-98f7-4a01-9e3a-1de53746da55",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "b16fe998-2ff9-4d87-b4bb-938cde9f89a5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>keyword</th>\n",
       "      <th>location</th>\n",
       "      <th>text</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2837</th>\n",
       "      <td>4081</td>\n",
       "      <td>displaced</td>\n",
       "      <td>UK  &amp; Germany</td>\n",
       "      <td>#Myanmar  Displaced #Rohingya at #Sittwe point...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1227</th>\n",
       "      <td>1768</td>\n",
       "      <td>buildings%20burning</td>\n",
       "      <td>New Hampshire</td>\n",
       "      <td>Witness video shows car explode behind burning...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4716</th>\n",
       "      <td>6706</td>\n",
       "      <td>lava</td>\n",
       "      <td>Medan,Indonesia</td>\n",
       "      <td>@YoungHeroesID Lava Blast &amp;amp; Power Red #Pan...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3437</th>\n",
       "      <td>4913</td>\n",
       "      <td>exploded</td>\n",
       "      <td>?????? in Yokohama Japan</td>\n",
       "      <td>Kakeru Teduka: Bfore 70years of today in Hiros...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5957</th>\n",
       "      <td>8508</td>\n",
       "      <td>screaming</td>\n",
       "      <td>Moore, OK</td>\n",
       "      <td>@noahshack he's hot &amp;amp; he can sing I'm scre...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1223</th>\n",
       "      <td>1762</td>\n",
       "      <td>buildings%20burning</td>\n",
       "      <td>England, United Kingdom</td>\n",
       "      <td>Must get hot in burning buildings\\n\\n-loses fo...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6589</th>\n",
       "      <td>9435</td>\n",
       "      <td>survivors</td>\n",
       "      <td>Anywhere Safe</td>\n",
       "      <td>@LawfulSurvivor T-Dog had been holed up in an ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        id              keyword                  location  \\\n",
       "2837  4081            displaced             UK  & Germany   \n",
       "1227  1768  buildings%20burning             New Hampshire   \n",
       "4716  6706                 lava           Medan,Indonesia   \n",
       "3437  4913             exploded  ?????? in Yokohama Japan   \n",
       "5957  8508            screaming                 Moore, OK   \n",
       "1223  1762  buildings%20burning   England, United Kingdom   \n",
       "6589  9435            survivors             Anywhere Safe   \n",
       "\n",
       "                                                   text  target  \n",
       "2837  #Myanmar  Displaced #Rohingya at #Sittwe point...       1  \n",
       "1227  Witness video shows car explode behind burning...       1  \n",
       "4716  @YoungHeroesID Lava Blast &amp; Power Red #Pan...       0  \n",
       "3437  Kakeru Teduka: Bfore 70years of today in Hiros...       1  \n",
       "5957  @noahshack he's hot &amp; he can sing I'm scre...       0  \n",
       "1223  Must get hot in burning buildings\\n\\n-loses fo...       1  \n",
       "6589  @LawfulSurvivor T-Dog had been holed up in an ...       1  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>keyword</th>\n",
       "      <th>location</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>730</th>\n",
       "      <td>2378</td>\n",
       "      <td>collapsed</td>\n",
       "      <td>NaN</td>\n",
       "      <td>I collapsed in the bathroom bcuz of Michael.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3215</th>\n",
       "      <td>10674</td>\n",
       "      <td>wounds</td>\n",
       "      <td>Dallas, TX</td>\n",
       "      <td>What they (dentists) don't tell u is how much ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2978</th>\n",
       "      <td>9848</td>\n",
       "      <td>trauma</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Gutted. 6 weeks to go. Suspected fracture to m...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2172</th>\n",
       "      <td>7269</td>\n",
       "      <td>nuclear%20disaster</td>\n",
       "      <td>NYC</td>\n",
       "      <td>Check out 'NOVA | Nuclear Meltdown Disaster' h...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1254</th>\n",
       "      <td>4125</td>\n",
       "      <td>drought</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Thought it was a drought!</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>468</th>\n",
       "      <td>1517</td>\n",
       "      <td>body%20bags</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Womens Stylish Metal Chain Pearls Solid Hanbag...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1185</th>\n",
       "      <td>3902</td>\n",
       "      <td>devastated</td>\n",
       "      <td>NaN</td>\n",
       "      <td>I'm literally devastated right now??</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         id             keyword    location  \\\n",
       "730    2378           collapsed         NaN   \n",
       "3215  10674              wounds  Dallas, TX   \n",
       "2978   9848              trauma         NaN   \n",
       "2172   7269  nuclear%20disaster         NYC   \n",
       "1254   4125             drought         NaN   \n",
       "468    1517         body%20bags         NaN   \n",
       "1185   3902          devastated         NaN   \n",
       "\n",
       "                                                   text  \n",
       "730        I collapsed in the bathroom bcuz of Michael.  \n",
       "3215  What they (dentists) don't tell u is how much ...  \n",
       "2978  Gutted. 6 weeks to go. Suspected fracture to m...  \n",
       "2172  Check out 'NOVA | Nuclear Meltdown Disaster' h...  \n",
       "1254                          Thought it was a drought!  \n",
       "468   Womens Stylish Metal Chain Pearls Solid Hanbag...  \n",
       "1185               I'm literally devastated right now??  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "display(df_train.sample(7))\n",
    "print()\n",
    "display(df_test.sample(7))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "bc2c5914-335b-4481-bbe2-dd36b987a321",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cleaned Train Data:\n",
      "                                                text  \\\n",
      "0  Our Deeds are the Reason of this #earthquake M...   \n",
      "1             Forest fire near La Ronge Sask. Canada   \n",
      "2  All residents asked to 'shelter in place' are ...   \n",
      "3  13,000 people receive #wildfires evacuation or...   \n",
      "4  Just got sent this photo from Ruby #Alaska as ...   \n",
      "\n",
      "                                          text_clean  \n",
      "0  our deeds are the reason of this earthquake ma...  \n",
      "1              forest fire near la ronge sask canada  \n",
      "2  all residents asked to shelter in place are be...  \n",
      "3  13000 people receive wildfires evacuation orde...  \n",
      "4  just got sent this photo from ruby alaska as s...  \n",
      "------------------------------------------------------------------------------------------\n",
      "Cleaned Test Data:\n",
      "                                                text  \\\n",
      "0                 Just happened a terrible car crash   \n",
      "1  Heard about #earthquake is different cities, s...   \n",
      "2  there is a forest fire at spot pond, geese are...   \n",
      "3           Apocalypse lighting. #Spokane #wildfires   \n",
      "4      Typhoon Soudelor kills 28 in China and Taiwan   \n",
      "\n",
      "                                          text_clean  \n",
      "0                 just happened a terrible car crash  \n",
      "1  heard about earthquake is different cities sta...  \n",
      "2  there is a forest fire at spot pond geese are ...  \n",
      "3              apocalypse lighting spokane wildfires  \n",
      "4      typhoon soudelor kills 28 in china and taiwan  \n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "import string\n",
    "import pandas as pd\n",
    "\n",
    "def clean_text(text):\n",
    "    if pd.isnull(text):\n",
    "        return \"\"\n",
    "    text = re.sub(r'https?://\\S+|www\\.\\S+', '', text)\n",
    "    text = re.sub(\n",
    "        r'['\n",
    "        u'\\U0001F600-\\U0001F64F'\n",
    "        u'\\U0001F300-\\U0001F5FF'\n",
    "        u'\\U0001F680-\\U0001F6FF'\n",
    "        u'\\U0001F1E0-\\U0001F1FF'\n",
    "        u'\\U00002702-\\U000027B0'\n",
    "        u'\\U000024C2-\\U0001F251'\n",
    "        ']+', \n",
    "        '', \n",
    "        text\n",
    "    )\n",
    "    text = re.sub(r'<.*?>|&([a-z0-9]+|#[0-9]{1,6}|#x[0-9a-f]{1,6});', '', text)\n",
    "    text = text.translate(str.maketrans('', '', string.punctuation))\n",
    "    text = text.lower()\n",
    "    text = \" \".join(text.split())\n",
    "    return text\n",
    "\n",
    "df_train['text_clean'] = df_train['text'].apply(clean_text)\n",
    "df_test['text_clean'] = df_test['text'].apply(clean_text)\n",
    "\n",
    "print(\"Cleaned Train Data:\")\n",
    "print(df_train[['text', 'text_clean']].head())\n",
    "\n",
    "print(\"---\" * 30)\n",
    "\n",
    "print(\"Cleaned Test Data:\")\n",
    "print(df_test[['text', 'text_clean']].head())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "bef54b92-222b-4c46-9353-5f935707295f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "id               0\n",
       "keyword         61\n",
       "location      2533\n",
       "text             0\n",
       "target           0\n",
       "text_clean       0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "34b0526e-8f3c-4e9e-87c3-e7a6139a8f4f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting nltk"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip is available: 24.0 -> 24.3.1\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "  Downloading nltk-3.9.1-py3-none-any.whl.metadata (2.9 kB)\n",
      "Collecting click (from nltk)\n",
      "  Downloading click-8.1.8-py3-none-any.whl.metadata (2.3 kB)\n",
      "Requirement already satisfied: joblib in d:\\brainworks\\projects\\tweet_analysis\\venv\\lib\\site-packages (from nltk) (1.4.2)\n",
      "Collecting regex>=2021.8.3 (from nltk)\n",
      "  Downloading regex-2024.11.6-cp312-cp312-win_amd64.whl.metadata (41 kB)\n",
      "     ---------------------------------------- 0.0/41.5 kB ? eta -:--:--\n",
      "     ------------------ ------------------- 20.5/41.5 kB 682.7 kB/s eta 0:00:01\n",
      "     -------------------------------------- 41.5/41.5 kB 666.1 kB/s eta 0:00:00\n",
      "Collecting tqdm (from nltk)\n",
      "  Downloading tqdm-4.67.1-py3-none-any.whl.metadata (57 kB)\n",
      "     ---------------------------------------- 0.0/57.7 kB ? eta -:--:--\n",
      "     ---------------------------------------- 57.7/57.7 kB 1.5 MB/s eta 0:00:00\n",
      "Requirement already satisfied: colorama in d:\\brainworks\\projects\\tweet_analysis\\venv\\lib\\site-packages (from click->nltk) (0.4.6)\n",
      "Downloading nltk-3.9.1-py3-none-any.whl (1.5 MB)\n",
      "   ---------------------------------------- 0.0/1.5 MB ? eta -:--:--\n",
      "   ------------------------- -------------- 0.9/1.5 MB 19.8 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 1.5/1.5 MB 19.2 MB/s eta 0:00:00\n",
      "Downloading regex-2024.11.6-cp312-cp312-win_amd64.whl (273 kB)\n",
      "   ---------------------------------------- 0.0/273.6 kB ? eta -:--:--\n",
      "   --------------------------------------- 273.6/273.6 kB 16.5 MB/s eta 0:00:00\n",
      "Downloading click-8.1.8-py3-none-any.whl (98 kB)\n",
      "   ---------------------------------------- 0.0/98.2 kB ? eta -:--:--\n",
      "   ---------------------------------------- 98.2/98.2 kB 5.9 MB/s eta 0:00:00\n",
      "Downloading tqdm-4.67.1-py3-none-any.whl (78 kB)\n",
      "   ---------------------------------------- 0.0/78.5 kB ? eta -:--:--\n",
      "   ---------------------------------------- 78.5/78.5 kB 4.3 MB/s eta 0:00:00\n",
      "Installing collected packages: tqdm, regex, click, nltk\n",
      "Successfully installed click-8.1.8 nltk-3.9.1 regex-2024.11.6 tqdm-4.67.1\n"
     ]
    }
   ],
   "source": [
    "!pip install nltk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "3b5b88f0-9ad6-466a-8d61-28df6d9d2ccc",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\Anand\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package punkt_tab to\n",
      "[nltk_data]     C:\\Users\\Anand\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Unzipping tokenizers\\punkt_tab.zip.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from nltk.tokenize import word_tokenize\n",
    "\n",
    "import nltk\n",
    "nltk.download('punkt')\n",
    "nltk.download('punkt_tab')\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "9b1d7d59-a788-4b73-a1bb-0691bd94dae5",
   "metadata": {},
   "outputs": [],
   "source": [
    "##we will tokenize the 'text_clean' column\n",
    "\n",
    "df_train['tokenized']=df_train['text_clean'].apply(word_tokenize)\n",
    "df_test['tokenized']=df_test['text_clean'].apply(word_tokenize)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "617fe237-13d9-4966-8d79-4b6944b4ced7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Data Tokenized:\n",
      "                                          text_clean  \\\n",
      "0  our deeds are the reason of this earthquake ma...   \n",
      "1              forest fire near la ronge sask canada   \n",
      "2  all residents asked to shelter in place are be...   \n",
      "3  13000 people receive wildfires evacuation orde...   \n",
      "4  just got sent this photo from ruby alaska as s...   \n",
      "\n",
      "                                           tokenized  \n",
      "0  [our, deeds, are, the, reason, of, this, earth...  \n",
      "1      [forest, fire, near, la, ronge, sask, canada]  \n",
      "2  [all, residents, asked, to, shelter, in, place...  \n",
      "3  [13000, people, receive, wildfires, evacuation...  \n",
      "4  [just, got, sent, this, photo, from, ruby, ala...  \n",
      "------------------------------------------------------------------------------------------\n",
      "Test Data Tokenized:\n",
      "                                          text_clean  \\\n",
      "0                 just happened a terrible car crash   \n",
      "1  heard about earthquake is different cities sta...   \n",
      "2  there is a forest fire at spot pond geese are ...   \n",
      "3              apocalypse lighting spokane wildfires   \n",
      "4      typhoon soudelor kills 28 in china and taiwan   \n",
      "\n",
      "                                           tokenized  \n",
      "0          [just, happened, a, terrible, car, crash]  \n",
      "1  [heard, about, earthquake, is, different, citi...  \n",
      "2  [there, is, a, forest, fire, at, spot, pond, g...  \n",
      "3         [apocalypse, lighting, spokane, wildfires]  \n",
      "4  [typhoon, soudelor, kills, 28, in, china, and,...  \n"
     ]
    }
   ],
   "source": [
    "# Display tokenized results\n",
    "print(\"Train Data Tokenized:\")\n",
    "print(df_train[['text_clean', 'tokenized']].head())\n",
    "\n",
    "print(\"---\" * 30)\n",
    "\n",
    "print(\"Test Data Tokenized:\")\n",
    "print(df_test[['text_clean', 'tokenized']].head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "480e5f45-a1d9-4e66-9064-380c4028dbbd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "D:\\Brainworks\\Projects\\Tweet_analysis\\venv\\nltk_data\\tokenizers\\punkt\n"
     ]
    }
   ],
   "source": [
    "import nltk\n",
    "print(nltk.data.find('tokenizers/punkt'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "f9d948a0-b026-4515-a164-1e345e73a1bb",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     D:/Brainworks/Projects/Tweet_analysis/venv...\n",
      "[nltk_data]   Unzipping tokenizers\\punkt.zip.\n"
     ]
    }
   ],
   "source": [
    "nltk.download('punkt', download_dir=\"D:/Brainworks/Projects/Tweet_analysis/venv\")\n",
    "import nltk\n",
    "nltk.data.path.append(\"D:/Brainworks/Projects/Tweet_analysis/venv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "799c61b4-8104-4e2a-a210-e50105efc9ce",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>keyword</th>\n",
       "      <th>location</th>\n",
       "      <th>text</th>\n",
       "      <th>target</th>\n",
       "      <th>text_clean</th>\n",
       "      <th>tokenized</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2120</th>\n",
       "      <td>3047</td>\n",
       "      <td>death</td>\n",
       "      <td>New York, New York</td>\n",
       "      <td>The first trial in the death of #CecilTheLion ...</td>\n",
       "      <td>0</td>\n",
       "      <td>the first trial in the death of cecilthelion w...</td>\n",
       "      <td>[the, first, trial, in, the, death, of, cecilt...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6264</th>\n",
       "      <td>8949</td>\n",
       "      <td>storm</td>\n",
       "      <td>Chicago, IL</td>\n",
       "      <td>How to prepare your #property for a #storm:\\n\\...</td>\n",
       "      <td>1</td>\n",
       "      <td>how to prepare your property for a storm</td>\n",
       "      <td>[how, to, prepare, your, property, for, a, storm]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1797</th>\n",
       "      <td>2579</td>\n",
       "      <td>crash</td>\n",
       "      <td>Melbourne, Australia</td>\n",
       "      <td>@DestinyTheGame @Bungie @PlayStation Getting k...</td>\n",
       "      <td>0</td>\n",
       "      <td>destinythegame bungie playstation getting kick...</td>\n",
       "      <td>[destinythegame, bungie, playstation, getting,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2499</th>\n",
       "      <td>3589</td>\n",
       "      <td>desolate</td>\n",
       "      <td>Macclesfield</td>\n",
       "      <td>@booksbyRoger TY for the follow Go To http://t...</td>\n",
       "      <td>0</td>\n",
       "      <td>booksbyroger ty for the follow go to brutally ...</td>\n",
       "      <td>[booksbyroger, ty, for, the, follow, go, to, b...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6531</th>\n",
       "      <td>9342</td>\n",
       "      <td>survived</td>\n",
       "      <td>London</td>\n",
       "      <td>Survived another tube strike with the last per...</td>\n",
       "      <td>0</td>\n",
       "      <td>survived another tube strike with the last per...</td>\n",
       "      <td>[survived, another, tube, strike, with, the, l...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        id   keyword                location  \\\n",
       "2120  3047     death      New York, New York   \n",
       "6264  8949     storm             Chicago, IL   \n",
       "1797  2579     crash    Melbourne, Australia   \n",
       "2499  3589  desolate            Macclesfield   \n",
       "6531  9342  survived                  London   \n",
       "\n",
       "                                                   text  target  \\\n",
       "2120  The first trial in the death of #CecilTheLion ...       0   \n",
       "6264  How to prepare your #property for a #storm:\\n\\...       1   \n",
       "1797  @DestinyTheGame @Bungie @PlayStation Getting k...       0   \n",
       "2499  @booksbyRoger TY for the follow Go To http://t...       0   \n",
       "6531  Survived another tube strike with the last per...       0   \n",
       "\n",
       "                                             text_clean  \\\n",
       "2120  the first trial in the death of cecilthelion w...   \n",
       "6264           how to prepare your property for a storm   \n",
       "1797  destinythegame bungie playstation getting kick...   \n",
       "2499  booksbyroger ty for the follow go to brutally ...   \n",
       "6531  survived another tube strike with the last per...   \n",
       "\n",
       "                                              tokenized  \n",
       "2120  [the, first, trial, in, the, death, of, cecilt...  \n",
       "6264  [how, to, prepare, your, property, for, a, storm]  \n",
       "1797  [destinythegame, bungie, playstation, getting,...  \n",
       "2499  [booksbyroger, ty, for, the, follow, go, to, b...  \n",
       "6531  [survived, another, tube, strike, with, the, l...  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>keyword</th>\n",
       "      <th>location</th>\n",
       "      <th>text</th>\n",
       "      <th>text_clean</th>\n",
       "      <th>tokenized</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2024</th>\n",
       "      <td>6816</td>\n",
       "      <td>loud%20bang</td>\n",
       "      <td>Kenya</td>\n",
       "      <td>k_matako_bot: Breaking news! Unconfirmed! I ju...</td>\n",
       "      <td>kmatakobot breaking news unconfirmed i just he...</td>\n",
       "      <td>[kmatakobot, breaking, news, unconfirmed, i, j...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>575</th>\n",
       "      <td>1871</td>\n",
       "      <td>burning</td>\n",
       "      <td>mumbai</td>\n",
       "      <td>hermancranston: WIRED : All these fires are bu...</td>\n",
       "      <td>hermancranston wired all these fires are burni...</td>\n",
       "      <td>[hermancranston, wired, all, these, fires, are...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>419</th>\n",
       "      <td>1358</td>\n",
       "      <td>blown%20up</td>\n",
       "      <td>NaN</td>\n",
       "      <td>@DodgersNation he was due to get blown up at l...</td>\n",
       "      <td>dodgersnation he was due to get blown up at le...</td>\n",
       "      <td>[dodgersnation, he, was, due, to, get, blown, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1957</th>\n",
       "      <td>6599</td>\n",
       "      <td>inundated</td>\n",
       "      <td>GroÌÙdeutsches Reich</td>\n",
       "      <td>Our children are being inundated with the fals...</td>\n",
       "      <td>our children are being inundated with the fals...</td>\n",
       "      <td>[our, children, are, being, inundated, with, t...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>285</th>\n",
       "      <td>922</td>\n",
       "      <td>bioterrorism</td>\n",
       "      <td>NaN</td>\n",
       "      <td>To fight bioterrorism sir.</td>\n",
       "      <td>to fight bioterrorism sir</td>\n",
       "      <td>[to, fight, bioterrorism, sir]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        id       keyword              location  \\\n",
       "2024  6816   loud%20bang                 Kenya   \n",
       "575   1871       burning                mumbai   \n",
       "419   1358    blown%20up                   NaN   \n",
       "1957  6599     inundated  GroÌÙdeutsches Reich   \n",
       "285    922  bioterrorism                   NaN   \n",
       "\n",
       "                                                   text  \\\n",
       "2024  k_matako_bot: Breaking news! Unconfirmed! I ju...   \n",
       "575   hermancranston: WIRED : All these fires are bu...   \n",
       "419   @DodgersNation he was due to get blown up at l...   \n",
       "1957  Our children are being inundated with the fals...   \n",
       "285                          To fight bioterrorism sir.   \n",
       "\n",
       "                                             text_clean  \\\n",
       "2024  kmatakobot breaking news unconfirmed i just he...   \n",
       "575   hermancranston wired all these fires are burni...   \n",
       "419   dodgersnation he was due to get blown up at le...   \n",
       "1957  our children are being inundated with the fals...   \n",
       "285                           to fight bioterrorism sir   \n",
       "\n",
       "                                              tokenized  \n",
       "2024  [kmatakobot, breaking, news, unconfirmed, i, j...  \n",
       "575   [hermancranston, wired, all, these, fires, are...  \n",
       "419   [dodgersnation, he, was, due, to, get, blown, ...  \n",
       "1957  [our, children, are, being, inundated, with, t...  \n",
       "285                      [to, fight, bioterrorism, sir]  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "display(df_train.sample(5))\n",
    "print()\n",
    "display(df_test.sample(5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "ba7e1022-db1c-4368-9802-68d59e7936e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "###we will do lowercase,Stopword removal, POS tagging, and Wordnet COnversion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "5ec2f0c9-6f45-4627-8b97-22a7207abefd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                           tokenized  \\\n",
      "0  [our, deeds, are, the, reason, of, this, earth...   \n",
      "1      [forest, fire, near, la, ronge, sask, canada]   \n",
      "2  [all, residents, asked, to, shelter, in, place...   \n",
      "3  [13000, people, receive, wildfires, evacuation...   \n",
      "4  [just, got, sent, this, photo, from, ruby, ala...   \n",
      "\n",
      "                                               lower  \n",
      "0  [our, deeds, are, the, reason, of, this, earth...  \n",
      "1      [forest, fire, near, la, ronge, sask, canada]  \n",
      "2  [all, residents, asked, to, shelter, in, place...  \n",
      "3  [13000, people, receive, wildfires, evacuation...  \n",
      "4  [just, got, sent, this, photo, from, ruby, ala...  \n"
     ]
    }
   ],
   "source": [
    "df_train['lower']=df_train['tokenized'].map(lambda tokens:[word.lower() for word in tokens])\n",
    "\n",
    "##display the first few rows of processed data\n",
    "print(df_train[['tokenized','lower']].head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "713d25ef-bba8-4f8e-b13e-d99802a12168",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>keyword</th>\n",
       "      <th>location</th>\n",
       "      <th>text</th>\n",
       "      <th>target</th>\n",
       "      <th>text_clean</th>\n",
       "      <th>tokenized</th>\n",
       "      <th>lower</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Our Deeds are the Reason of this #earthquake M...</td>\n",
       "      <td>1</td>\n",
       "      <td>our deeds are the reason of this earthquake ma...</td>\n",
       "      <td>[our, deeds, are, the, reason, of, this, earth...</td>\n",
       "      <td>[our, deeds, are, the, reason, of, this, earth...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>4</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Forest fire near La Ronge Sask. Canada</td>\n",
       "      <td>1</td>\n",
       "      <td>forest fire near la ronge sask canada</td>\n",
       "      <td>[forest, fire, near, la, ronge, sask, canada]</td>\n",
       "      <td>[forest, fire, near, la, ronge, sask, canada]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>5</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>All residents asked to 'shelter in place' are ...</td>\n",
       "      <td>1</td>\n",
       "      <td>all residents asked to shelter in place are be...</td>\n",
       "      <td>[all, residents, asked, to, shelter, in, place...</td>\n",
       "      <td>[all, residents, asked, to, shelter, in, place...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>6</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>13,000 people receive #wildfires evacuation or...</td>\n",
       "      <td>1</td>\n",
       "      <td>13000 people receive wildfires evacuation orde...</td>\n",
       "      <td>[13000, people, receive, wildfires, evacuation...</td>\n",
       "      <td>[13000, people, receive, wildfires, evacuation...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>7</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Just got sent this photo from Ruby #Alaska as ...</td>\n",
       "      <td>1</td>\n",
       "      <td>just got sent this photo from ruby alaska as s...</td>\n",
       "      <td>[just, got, sent, this, photo, from, ruby, ala...</td>\n",
       "      <td>[just, got, sent, this, photo, from, ruby, ala...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   id keyword location                                               text  \\\n",
       "0   1     NaN      NaN  Our Deeds are the Reason of this #earthquake M...   \n",
       "1   4     NaN      NaN             Forest fire near La Ronge Sask. Canada   \n",
       "2   5     NaN      NaN  All residents asked to 'shelter in place' are ...   \n",
       "3   6     NaN      NaN  13,000 people receive #wildfires evacuation or...   \n",
       "4   7     NaN      NaN  Just got sent this photo from Ruby #Alaska as ...   \n",
       "\n",
       "   target                                         text_clean  \\\n",
       "0       1  our deeds are the reason of this earthquake ma...   \n",
       "1       1              forest fire near la ronge sask canada   \n",
       "2       1  all residents asked to shelter in place are be...   \n",
       "3       1  13000 people receive wildfires evacuation orde...   \n",
       "4       1  just got sent this photo from ruby alaska as s...   \n",
       "\n",
       "                                           tokenized  \\\n",
       "0  [our, deeds, are, the, reason, of, this, earth...   \n",
       "1      [forest, fire, near, la, ronge, sask, canada]   \n",
       "2  [all, residents, asked, to, shelter, in, place...   \n",
       "3  [13000, people, receive, wildfires, evacuation...   \n",
       "4  [just, got, sent, this, photo, from, ruby, ala...   \n",
       "\n",
       "                                               lower  \n",
       "0  [our, deeds, are, the, reason, of, this, earth...  \n",
       "1      [forest, fire, near, la, ronge, sask, canada]  \n",
       "2  [all, residents, asked, to, shelter, in, place...  \n",
       "3  [13000, people, receive, wildfires, evacuation...  \n",
       "4  [just, got, sent, this, photo, from, ruby, ala...  "
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "c5e1371a-8e40-4329-aea0-1d2956ab17ec",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                               lower  \\\n",
      "0  [our, deeds, are, the, reason, of, this, earth...   \n",
      "1      [forest, fire, near, la, ronge, sask, canada]   \n",
      "2  [all, residents, asked, to, shelter, in, place...   \n",
      "3  [13000, people, receive, wildfires, evacuation...   \n",
      "4  [just, got, sent, this, photo, from, ruby, ala...   \n",
      "\n",
      "                                   stopwords_removed  \n",
      "0  [deeds, reason, earthquake, may, allah, forgiv...  \n",
      "1      [forest, fire, near, la, ronge, sask, canada]  \n",
      "2  [residents, asked, shelter, place, notified, o...  \n",
      "3  [13000, people, receive, wildfires, evacuation...  \n",
      "4  [got, sent, photo, ruby, alaska, smoke, wildfi...  \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\Anand\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "from nltk.corpus import stopwords\n",
    "\n",
    "##Ensure stopwords are available\n",
    "nltk.download('stopwords')\n",
    "stop=set(stopwords.words('english'))\n",
    "\n",
    "###Remove stopwords from the 'lower' column\n",
    "df_train['stopwords_removed']=df_train['lower'].map(lambda tokens:[word for word in tokens if word not in stop])\n",
    "\n",
    "##display the first few rows with stopwords removed\n",
    "print(df_train[['lower','stopwords_removed']].head())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "ca638bf7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>keyword</th>\n",
       "      <th>location</th>\n",
       "      <th>text</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Our Deeds are the Reason of this #earthquake M...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>4</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Forest fire near La Ronge Sask. Canada</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>5</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>All residents asked to 'shelter in place' are ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>6</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>13,000 people receive #wildfires evacuation or...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>7</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Just got sent this photo from Ruby #Alaska as ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7608</th>\n",
       "      <td>10869</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Two giant cranes holding a bridge collapse int...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7609</th>\n",
       "      <td>10870</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>@aria_ahrary @TheTawniest The out of control w...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7610</th>\n",
       "      <td>10871</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>M1.94 [01:04 UTC]?5km S of Volcano Hawaii. htt...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7611</th>\n",
       "      <td>10872</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Police investigating after an e-bike collided ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7612</th>\n",
       "      <td>10873</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>The Latest: More Homes Razed by Northern Calif...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>7613 rows × 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         id keyword location  \\\n",
       "0         1     NaN      NaN   \n",
       "1         4     NaN      NaN   \n",
       "2         5     NaN      NaN   \n",
       "3         6     NaN      NaN   \n",
       "4         7     NaN      NaN   \n",
       "...     ...     ...      ...   \n",
       "7608  10869     NaN      NaN   \n",
       "7609  10870     NaN      NaN   \n",
       "7610  10871     NaN      NaN   \n",
       "7611  10872     NaN      NaN   \n",
       "7612  10873     NaN      NaN   \n",
       "\n",
       "                                                   text  target  \n",
       "0     Our Deeds are the Reason of this #earthquake M...       1  \n",
       "1                Forest fire near La Ronge Sask. Canada       1  \n",
       "2     All residents asked to 'shelter in place' are ...       1  \n",
       "3     13,000 people receive #wildfires evacuation or...       1  \n",
       "4     Just got sent this photo from Ruby #Alaska as ...       1  \n",
       "...                                                 ...     ...  \n",
       "7608  Two giant cranes holding a bridge collapse int...       1  \n",
       "7609  @aria_ahrary @TheTawniest The out of control w...       1  \n",
       "7610  M1.94 [01:04 UTC]?5km S of Volcano Hawaii. htt...       1  \n",
       "7611  Police investigating after an e-bike collided ...       1  \n",
       "7612  The Latest: More Homes Razed by Northern Calif...       1  \n",
       "\n",
       "[7613 rows x 5 columns]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0rc2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
